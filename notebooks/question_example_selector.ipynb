{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select by Maximal Marginal Relevance example selector (MMR)\n",
    "Selecting an example question matching the user's question using maximal marginal relevance.\n",
    "\"MMR not only finds the similarities but also trying it best to make them diverse. In other word, it will tell the system to select the first example as similar to the input as possible, but the subsequent example should be different to the previous one as much as possible but still similar to the input.\"\n",
    "\n",
    "Source: https://medium.com/@larry_nguyen/langchain-101-lesson-2-example-selectors-37b891ca9268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from faiss-cpu) (1.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/14.6 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------- 0.2/14.6 MB 10.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/14.6 MB 5.4 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.6/14.6 MB 5.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/14.6 MB 5.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/14.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.7/14.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/14.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.6 MB 5.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.5/14.6 MB 5.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/14.6 MB 5.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.1/14.6 MB 5.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/14.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.3/14.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.3/14.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.9/14.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.9/14.6 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.5/14.6 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.7/14.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.2/14.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.5/14.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.7/14.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.2/14.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.2/14.6 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.6 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.6/14.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.6/14.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.1/14.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.5/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.5/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.7/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.8/14.6 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.2/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.2/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.6/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.0/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.2/14.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.9/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.0/14.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\dinab\\miniconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dinab\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial example test from online article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]\n",
    "\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    examples,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(),\n",
    "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS,\n",
    "    # The number of examples to produce.\n",
    "    k=2,\n",
    ")\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "# Input is a feeling, so should select the happy/sad example as the first one\n",
    "print(mmr_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the method to our use case (example questions) with MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the question similar to the input question\n",
      "\n",
      "Similar Question: Wat zijn de laatste 10 besluiten en wanneer zijn deze gepubliceerd?\n",
      "\n",
      "Similar Question: Where can I go swimming?\n",
      "\n",
      "Your Question: What were the last decisions about high school?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Similar Question: {question}\",\n",
    ")\n",
    "\n",
    "with open('questions_and_queries.json', 'r', encoding='utf-8') as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "# Change the key from \"user_question\" to \"question\"\n",
    "example_questions = [{\"question\": item[\"user_question\"]} for item in example_data]\n",
    "\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    example_questions,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(),\n",
    "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS,\n",
    "    # The number of examples to produce.\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the question similar to the input question\",\n",
    "    suffix=\"Your Question: {question}\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "# Input is a feeling, so should select the happy/sad example as the first one\n",
    "print(mmr_prompt.format(question=\"What were the last decisions about high school?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select by Semantic Similarity example selector (SS)\n",
    "\n",
    "Source: https://python.langchain.com/v0.1/docs/modules/model_io/prompts/example_selectors/similarity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    examples,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(),\n",
    "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS,\n",
    "    # The number of examples to produce.\n",
    "    k=2,\n",
    ")\n",
    "ss_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "print(ss_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the method to our use case (example questions) with SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the question similar to the input question\n",
      "\n",
      "Similar Question: Where can I go swimming?\n",
      "\n",
      "Similar Question: How can I do my recycling?\n",
      "\n",
      "Your Question: Where can I bike?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Similar Question: {question}\",\n",
    ")\n",
    "\n",
    "with open('questions_and_queries.json', 'r', encoding='utf-8') as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "# Change the key from \"user_question\" to \"question\"\n",
    "example_questions = [{\"question\": item[\"user_question\"]} for item in example_data]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    example_questions,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(),\n",
    "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS,\n",
    "    # The number of examples to produce.\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "ss_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the question similar to the input question\",\n",
    "    suffix=\"Your Question: {question}\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "# Input is a feeling, so should select the happy/sad example as the first one\n",
    "print(ss_prompt.format(question=\"Where can I bike?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the question similar to the input question\n",
      "\n",
      "Similar Question: Wat waren de laatste 10 beslissingen met betrekking tot het milieu in Gent?\n",
      "\n",
      "Similar Question: Welke besluiten heeft de burgemeester genomen?\n",
      "\n",
      "Your Question: What are the recent decisions in Gent?\n"
     ]
    }
   ],
   "source": [
    "print(ss_prompt.format(question=\"What are the recent decisions in Gent?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic textual similarity with SentenceTransformers\n",
    "Sources: \n",
    "- https://www.sbert.net/examples/applications/semantic-search/README.html\n",
    "- https://sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinab\\miniconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinab\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dinab\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wat waren de laatste 10 beslissingen met betrekking tot het milieu in Gent?',\n",
       " 'Welke maatregelen worden er tijdens de bouw genomen voor stofbeheersing en -reductie?',\n",
       " 'How can I do my recycling?',\n",
       " 'Where can I go swimming?',\n",
       " 'Wat zijn de laatste 10 besluiten en wanneer zijn deze gepubliceerd?',\n",
       " 'Welke besluiten heeft de burgemeester genomen?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load example data\n",
    "with open('questions_and_queries.json', 'r', encoding='utf-8') as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "# Extract example questions\n",
    "example_questions = [item[\"user_question\"] for item in example_data]\n",
    "\n",
    "example_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = embedder.encode(example_questions, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where can I go biking?\n",
      "Top most similar sentence in questions:\n",
      "Where can I go swimming? (Score: 0.5896)\n",
      "How can I do my recycling? (Score: 0.1440)\n"
     ]
    }
   ],
   "source": [
    "question = \"Where can I go biking?\"\n",
    "top_k = min(2, len(example_questions))\n",
    "question_embedding = embedder.encode(question, convert_to_tensor=True)\n",
    "similarity_scores = embedder.similarity(question_embedding, question_embeddings)[0]\n",
    "scores, indices = torch.topk(similarity_scores, k=top_k)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Top most similar sentence in questions:\")\n",
    "\n",
    "for score, idx in zip(scores, indices):\n",
    "    print(example_questions[idx], \"(Score: {:.4f})\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
